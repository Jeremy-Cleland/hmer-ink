# Enhanced Fast Training Configuration for HMER-Ink

# Data settings
data:
  data_dir: "data"
  train_dirs: ["train"]  # Use only main training data
  valid_dir: "valid"
  test_dir: "test"
  max_seq_length: 384  # Reduced
  max_token_length: 192  # Reduced
  use_synthetic: false  # Skip synthetic data for faster training
  normalization:
    x_range: [-1, 1]
    y_range: [-1, 1]
    time_range: [0, 1]
  augmentation:
    enabled: true
    scale_range: [0.8, 1.2]  # Less aggressive scaling
    rotation_range: [-10, 10]  # Less rotation
    translation_range: [-0.1, 0.1]
    stroke_dropout_prob: 0.05
    jitter_scale: 0.01
    stroke_thickness_range: [1.0, 2.0]

# Model architecture (lighter)
model:
  name: "transformer_encoder_decoder"
  encoder:
    type: "transformer"
    input_dim: 4  # x, y, t, pen_state
    embedding_dim: 256  # Reduced
    num_layers: 3  # Fewer layers
    num_heads: 8
    dropout: 0.1
    position_encoding: "sinusoidal"
  decoder:
    type: "transformer"
    embedding_dim: 256  # Reduced
    num_layers: 3  # Fewer layers
    num_heads: 8
    dropout: 0.1
    max_length: 192

# Training settings - optimized for speed
training:
  batch_size: 64  # Original batch size for faster training
  learning_rate: 0.0005  # Slightly higher for faster convergence
  weight_decay: 0.0001
  num_epochs: 50  # Fewer epochs
  early_stopping_patience: 8  # Increased patience to ensure convergence
  lr_scheduler:
    type: "reduce_on_plateau"
    factor: 0.5
    patience: 2  # Quicker LR reduction
    threshold: 0.001
  optimizer: "adamw"
  use_amp: true  # Mixed precision for faster training
  device: "mps"  # For Apple Silicon
  num_workers: 4
  gradient_accumulation_steps: 8 # Original steps
  save_every_n_epochs: 1  # Save more frequently
  validate_every_n_steps: 3000  # Validate more frequently
  clip_grad_norm: 1.0

# MPS specific optimizations
mps_configuration:
  enable_mps_fallback: true
  verbose: false  # Reduce logging noise
  high_watermark_ratio: 0.0
  prefer_channels_last: true
  enable_early_graph_capture: true
  separate_device_alloc: true
  use_system_allocator: true

# Evaluation settings
evaluation:
  batch_size: 32
  device: "mps"
  metrics: ["edit_distance", "character_error_rate", "expression_recognition_rate", "symbol_accuracy", "token_error_rate"]
  beam_size: 4  # Increased for better evaluation
  # Include detailed error examples for better monitoring
  num_error_examples: 10

# Outputs
output:
  checkpoint_dir: "outputs/checkpoints"
  log_dir: "outputs/logs"
  use_wandb: true  # Enable Weights & Biases for tracking progress
  project_name: "hmer-ink-fast"
  tensorboard: false  # Disable tensorboard
  save_best_k: 2  # Save more best models
  monitor_metric: "expression_recognition_rate"
  monitor_mode: "max"